#!/bin/bash

#SBATCH --job-name=calcs-semantic-robustness-check # Job name
#SBATCH --error=./logs/%j%x.err # error file
#SBATCH --output=./logs/%j%x.out # output log file
#SBATCH --time=24:00:00 # 10 hours of wall time
#SBATCH --nodes=1  # 1 GPU node
#SBATCH --mem=16000 # 16 GB of RAM
#SBATCH --nodelist=ws-l4-019

echo "Evaluate aya"
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_switch_points_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_switch_points_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_switch_points_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_switch_points_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_switch_points_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_switch_points_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_natural_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.25_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.5_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.75_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-1_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-2_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-3_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-4_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-5_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero

#python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_natural_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-1_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-2_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-3_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-4_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-5_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero

#python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_natural_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-1_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-2_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-3_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-4_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-5_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_natural_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-1_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method mean --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-2_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method mean --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-3_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method mean --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-4_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method mean --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-5_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method mean --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_natural_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-1_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-2_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-3_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-4_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-5_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_natural_codemixing_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.25_codemixing_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.5_codemixing_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file aya-expanse-8b_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_synth_0.75_codemixing_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-1_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-2_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-3_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-4_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-aya-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name CohereForAI/aya-expanse-8b --output_file aya-expanse-8b_random-5_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero

# echo "Evaluate bloom"
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_switch_points_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_switch_points_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_switch_points_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_switch_points_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_switch_points_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_switch_points_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_natural_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.25_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.5_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.75_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-1_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-2_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-3_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-4_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-5_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file bloom-7b1_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_natural_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-1_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-2_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-3_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-4_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-5_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file bloom-7b1_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_natural_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-1_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-2_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-3_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-4_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-5_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl  --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file bloom-7b1_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_natural_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method mean --mean_ablation_file mean_ablation/mean_ablation_values_synth_0.5_codemixed_en_hi.pkl
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-1_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-2_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-3_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-4_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-5_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl  --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file bloom-7b1_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_natural_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-1_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-2_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-3_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-4_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-5_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file bloom-7b1_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_natural_codemixing_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.25_codemixing_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.5_codemixing_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file bloom-7b1_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_synth_0.75_codemixing_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-1_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-2_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-3_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-4_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-bloom-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name bigscience/bloom-7b1 --output_file bloom-7b1_random-5_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero

# echo "Evaluate llama"
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_switch_points_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_switch_points_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_switch_points_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_switch_points_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_switch_points_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_switch_points_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_natural_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.25_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.5_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.75_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-1_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-2_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-3_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-4_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-5_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_natural_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-1_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-2_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-3_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-4_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-5_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl  --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_natural_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-1_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-2_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-3_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-4_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-5_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_natural_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-1_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-2_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-3_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-4_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-5_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_natural_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-1_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-2_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-3_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-4_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-5_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_natural_codemixing_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.25_codemixing_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.5_codemixing_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Llama-3.2-3B_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_synth_0.75_codemixing_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-1_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-2_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-3_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-4_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-llama3-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name meta-llama/Llama-3.2-3B --output_file Llama-3.2-3B_random-5_semantic_scores_zero-ablate_en-hi.pkl --ablation_method zero

# echo "Evaluate qwen"
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_switch_points_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_switch_points_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_switch_points_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_switch_points_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_switch_points_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_switch_point_semantics_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_switch_points_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_natural_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.25_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.5_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.75_codemixing_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-1_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-2_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-3_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-4_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_natural_cmix.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-5_semantic_scores_zero-ablate_nat-en-hi-hi.pkl --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_natural_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-1_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-2_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-3_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-4_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.25.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-5_semantic_scores_zero-ablate_synth-0.25-en-hi-en.pkl --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_natural_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-1_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-2_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-3_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-4_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_en.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-5_semantic_scores_zero-ablate_synth-0.5-en-hi-en.pkl --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_natural_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-1_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-2_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-3_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-4_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.5.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-5_semantic_scores_zero-ablate_synth-0.5-en-hi-hi.pkl --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_natural_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.25_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.5_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.75_codemixing_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-1_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-2_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-3_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-4_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_synth_cmix_proba_0.75.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-5_semantic_scores_zero-ablate_synth-0.75-en-hi-hi.pkl  --ablation_method zero

# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_natural_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_natural_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_natural_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_natural_codemixing_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.25_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.25_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.25_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.25_codemixing_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.5_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.5_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.5_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.5_codemixing_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.75_codemixing_lang_en-hi_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.75_codemixing_lang_en-hi_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file Qwen2.5-7B_synth_0.75_codemixing_subset.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_synth_0.75_codemixing_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-1.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-1_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-2.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-2_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-3.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-3_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-4.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-4_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
# python semantic_similarity_experiment.py --neuron_file random-neurons-qwen-5.pkl --input_file_1 datasets/calcs_english-hinglish/dev_hi.txt --input_file_2 datasets/calcs_english-hinglish/dev_en.txt --batch_size 8 --model_name Qwen/Qwen2.5-7B --output_file Qwen2.5-7B_random-5_semantic_scores_zero-ablate_en-hi.pkl  --ablation_method zero
echo "Finished"
