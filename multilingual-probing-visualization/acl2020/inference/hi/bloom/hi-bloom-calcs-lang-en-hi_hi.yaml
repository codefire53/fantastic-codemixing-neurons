dataset:
  observation_fieldnames:
     - index
     - sentence
     - lemma_sentence
     - upos_sentence
     - xpos_sentence
     - morph
     - head_indices
     - governance_relations
     - secondary_relations
     - extra_info
     - langs
     - embeddings
  corpus:
    root: ../datasets/calcs_english-hinglish
    train_path: train.conllu
    dev_path: dev.conllu
    test_path: test.conllu 
    inference_path: dev_hi.txt
    use_translit: false
  embeddings:
    type: token #(token,subword)
    root: ../embeddings/bloom
    train_path: train_hi.hdf5
    dev_path: dev_hi.hdf5
    test_path: test_hi.hdf5
    inference_path: calcs.hdf5
  edges:
    root: ../edges/bloom
    inference_path: hi_dev_hi_lang-en-hi.pkl 
  keys:
    train: ['hi']
    dev: ['hi']
    test: ['hi']
    inference: ['hi']
  batch_size: 8
model:
  hidden_dim: 4096 # ELMo hidden dim
  #embedding_dim: 1024 # ELMo word embedding dim
  model_type: GPT-disk # BERT-disk, ELMo-disk, 
  use_disk: True
  model_layer: 29 # BERT-base: (1,...,12); ELMo: (1,2,3)
  backbone_model: bigscience/bloom-7b1
probe:
  task_signature: word_pair # word, word_pair
  task_name: parse-distance
  maximum_rank: 128
  psd_parameters: True
  diagonal: False
  params_path: multi_predictor.params
probe_training:
  epochs: 30
  loss: L1
reporting:
  root: ../probing_outputs/bloom
  observation_paths:
    train_path: train.observations
    dev_path: dev.observations
    test_path: test.observations
  prediction_paths:
    train_path: train.predictions
    dev_path: dev.predictions
    test_path: test.predictions
  reporting_methods:
    - spearmanr
      #- image_examples
    - uuas
    - proj_acc
    - adj_acc
