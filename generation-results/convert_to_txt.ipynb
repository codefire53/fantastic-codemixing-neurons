{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:00<00:00, 804036.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "filepath = 'outputs/qwen-instruct/generated_texts_en-hi_conditioned_qwen-7b-instruct_switch_points_activated_multiplier_0.pkl'\n",
    "outpath = 'outputs/qwen-instruct/generated_texts_en-hi_conditioned_qwen-7b-instruct_switch_points__activated_multiplier_0.txt'\n",
    "use_translit = False\n",
    "with open(filepath, 'rb') as f:\n",
    "    lst = pickle.load(f)\n",
    "divider = 'assistant\\n'\n",
    "examples = []\n",
    "print(len(lst))\n",
    "for instance in tqdm(lst):\n",
    "    lines = instance.split(divider)\n",
    "    model_output = lines[-1]\n",
    "    # cands = []\n",
    "    # cands_cnt = dict()\n",
    "    # max_cand, max_cand_cnt = \"\", 0\n",
    "    # for line in lines:\n",
    "    #     if 'Hindi English' in line:\n",
    "    #         splitted_line = line.split('Hindi English:')[-1]\n",
    "    #         splitted_line = splitted_line.strip()\n",
    "    #         cands.append(splitted_line)\n",
    "    #         if splitted_line not in cands_cnt:\n",
    "    #             cands_cnt[splitted_line] = 0\n",
    "    #         cands_cnt[splitted_line] += 1\n",
    "    #         if max_cand_cnt < cands_cnt[splitted_line]:\n",
    "    #             max_cand_cnt = cands_cnt[splitted_line]\n",
    "    #             max_cand = splitted_line\n",
    "    # translation = max_cand if max_cand_cnt > 1 else cands[-1]\n",
    "    # if use_translit:\n",
    "    #     translation = transliterator.translit_sentence(translation, lang_code='hi')\n",
    "    examples.append(model_output.strip().replace('\\n', ' ').replace('\\r\\n', ' '))\n",
    "\n",
    "with open(outpath, 'w') as f:\n",
    "    f.write('\\n'.join(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.\\nuser\\nPlease write down the output only in latin script. Generate only the translation. Do not output any extra test. Translate an English sentence into a Hindi-English codemixed sentence.\\nEnglish: hello\\nHindi English: \\nassistant\\nhello world'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = '../datasets/calcs_english-hinglish/dev_hi_og.txt'\n",
    "out_path = '../datasets/calcs_english-hinglish/dev_hi_og_new.txt'\n",
    "hi_texts = []\n",
    "with open(in_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        col = line.split('\\t')\n",
    "        hi_text = col[1]\n",
    "        hi_texts.append(hi_text)\n",
    "with open(out_path, 'w') as f:\n",
    "    f.write('\\n'.join(hi_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ai4bharat-transliteration\n",
      "  Using cached ai4bharat_transliteration-1.1.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydload (from ai4bharat-transliteration)\n",
      "  Using cached pydload-1.0.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting flask (from ai4bharat-transliteration)\n",
      "  Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting flask-cors (from ai4bharat-transliteration)\n",
      "  Using cached Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting gevent (from ai4bharat-transliteration)\n",
      "  Using cached gevent-24.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting sacremoses (from ai4bharat-transliteration)\n",
      "  Using cached sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: pandas in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from ai4bharat-transliteration) (2.2.3)\n",
      "Requirement already satisfied: tqdm in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from ai4bharat-transliteration) (4.67.1)\n",
      "Collecting ujson (from ai4bharat-transliteration)\n",
      "  Using cached ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting mock (from ai4bharat-transliteration)\n",
      "  Using cached mock-5.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting tensorboardX (from ai4bharat-transliteration)\n",
      "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pyarrow in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from ai4bharat-transliteration) (18.1.0)\n",
      "Collecting fairseq (from ai4bharat-transliteration)\n",
      "  Using cached fairseq-0.12.2.tar.gz (9.6 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting urduhack (from ai4bharat-transliteration)\n",
      "  Using cached urduhack-1.1.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting indic-nlp-library (from ai4bharat-transliteration)\n",
      "  Using cached indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: cffi in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from fairseq->ai4bharat-transliteration) (1.17.1)\n",
      "Collecting cython (from fairseq->ai4bharat-transliteration)\n",
      "  Using cached Cython-3.0.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting hydra-core<1.1,>=1.0.7 (from fairseq->ai4bharat-transliteration)\n",
      "  Using cached hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting omegaconf<2.1 (from fairseq->ai4bharat-transliteration)\n",
      "  Using cached omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\n",
      "\u001b[33mWARNING: Ignoring version 2.0.6 of omegaconf since it has invalid metadata:\n",
      "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl (from fairseq->ai4bharat-transliteration) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
      "    PyYAML (>=5.1.*)\n",
      "            ~~~~~~^\n",
      "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached omegaconf-2.0.5-py3-none-any.whl.metadata (3.0 kB)\n",
      "\u001b[33mWARNING: Ignoring version 2.0.5 of omegaconf since it has invalid metadata:\n",
      "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/e5/f6/043b6d255dd6fbf2025110cea35b87f4c5100a181681d8eab496269f0d5b/omegaconf-2.0.5-py3-none-any.whl (from fairseq->ai4bharat-transliteration) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
      "    PyYAML (>=5.1.*)\n",
      "            ~~~~~~^\n",
      "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached omegaconf-2.0.4-py3-none-any.whl.metadata (3.0 kB)\n",
      "\u001b[33mWARNING: Ignoring version 2.0.4 of omegaconf since it has invalid metadata:\n",
      "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/92/b1/4f3023143436f12c98bab53f0b3db617bd18a7d223627d5030e13a7b4fc2/omegaconf-2.0.4-py3-none-any.whl (from fairseq->ai4bharat-transliteration) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
      "    PyYAML (>=5.1.*)\n",
      "            ~~~~~~^\n",
      "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached omegaconf-2.0.3-py3-none-any.whl.metadata (3.0 kB)\n",
      "\u001b[33mWARNING: Ignoring version 2.0.3 of omegaconf since it has invalid metadata:\n",
      "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/29/08/a88210c2c1aa0a3f65f05d8a6c98939ccb84b6fb982aa6567dec4e6773f9/omegaconf-2.0.3-py3-none-any.whl (from fairseq->ai4bharat-transliteration) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
      "    PyYAML (>=5.1.*)\n",
      "            ~~~~~~^\n",
      "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached omegaconf-2.0.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "\u001b[33mWARNING: Ignoring version 2.0.2 of omegaconf since it has invalid metadata:\n",
      "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/72/fe/f8d162aa059fb4f327fd75144dd69aa7e8acbb6d8d37013e4638c8490e0b/omegaconf-2.0.2-py3-none-any.whl (from fairseq->ai4bharat-transliteration) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
      "    PyYAML (>=5.1.*)\n",
      "            ~~~~~~^\n",
      "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached omegaconf-2.0.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "\u001b[33mWARNING: Ignoring version 2.0.1 of omegaconf since it has invalid metadata:\n",
      "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/86/ec/605805e60abdb025b06664d107335031bb8ebdc52e0a90bdbad6a7130279/omegaconf-2.0.1-py3-none-any.whl (from fairseq->ai4bharat-transliteration) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
      "    PyYAML (>=5.1.*)\n",
      "            ~~~~~~^\n",
      "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached omegaconf-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from fairseq->ai4bharat-transliteration) (1.26.4)\n",
      "Requirement already satisfied: regex in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from fairseq->ai4bharat-transliteration) (2024.11.6)\n",
      "Collecting sacrebleu>=1.4.12 (from fairseq->ai4bharat-transliteration)\n",
      "  Using cached sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "Requirement already satisfied: torch in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from fairseq->ai4bharat-transliteration) (2.5.1)\n",
      "Collecting bitarray (from fairseq->ai4bharat-transliteration)\n",
      "  Using cached bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: torchaudio>=0.8.0 in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from fairseq->ai4bharat-transliteration) (2.5.1)\n",
      "Collecting Werkzeug>=3.1 (from flask->ai4bharat-transliteration)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from flask->ai4bharat-transliteration) (3.1.4)\n",
      "Collecting itsdangerous>=2.2 (from flask->ai4bharat-transliteration)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from flask->ai4bharat-transliteration) (8.1.8)\n",
      "Collecting blinker>=1.9 (from flask->ai4bharat-transliteration)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting zope.event (from gevent->ai4bharat-transliteration)\n",
      "  Using cached zope.event-5.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting zope.interface (from gevent->ai4bharat-transliteration)\n",
      "  Using cached zope.interface-7.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: greenlet>=3.1.1 in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from gevent->ai4bharat-transliteration) (3.1.1)\n",
      "Collecting sphinx-argparse (from indic-nlp-library->ai4bharat-transliteration)\n",
      "  Using cached sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting sphinx-rtd-theme (from indic-nlp-library->ai4bharat-transliteration)\n",
      "  Using cached sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting morfessor (from indic-nlp-library->ai4bharat-transliteration)\n",
      "  Using cached Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from pandas->ai4bharat-transliteration) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from pandas->ai4bharat-transliteration) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from pandas->ai4bharat-transliteration) (2024.2)\n",
      "Collecting progressbar2 (from pydload->ai4bharat-transliteration)\n",
      "  Using cached progressbar2-4.5.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: requests in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from pydload->ai4bharat-transliteration) (2.32.3)\n",
      "Requirement already satisfied: joblib in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from sacremoses->ai4bharat-transliteration) (1.4.2)\n",
      "Requirement already satisfied: packaging in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from tensorboardX->ai4bharat-transliteration) (24.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages (from tensorboardX->ai4bharat-transliteration) (5.29.3)\n",
      "Collecting tf2crf (from urduhack->ai4bharat-transliteration)\n",
      "  Using cached tf2crf-0.1.33-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting tensorflow-datasets~=3.1 (from urduhack->ai4bharat-transliteration)\n",
      "  Using cached tensorflow_datasets-3.2.1-py3-none-any.whl.metadata (4.8 kB)\n",
      "INFO: pip is looking at multiple versions of urduhack to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting urduhack (from ai4bharat-transliteration)\n",
      "  Using cached urduhack-1.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Using cached urduhack-1.0.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Using cached urduhack-1.0.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Using cached urduhack-1.0.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Using cached urduhack-1.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "  Using cached urduhack-0.3.4-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting transformers~=2.10 (from urduhack->ai4bharat-transliteration)\n",
      "  Using cached transformers-2.11.0-py3-none-any.whl.metadata (45 kB)\n",
      "Collecting urduhack (from ai4bharat-transliteration)\n",
      "  Using cached urduhack-0.3.3-py3-none-any.whl.metadata (7.2 kB)\n",
      "INFO: pip is still looking at multiple versions of urduhack to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached urduhack-0.3.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting tensorflow~=2.2 (from urduhack->ai4bharat-transliteration)\n",
      "  Using cached tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting urduhack (from ai4bharat-transliteration)\n",
      "  Using cached urduhack-0.3.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached urduhack-0.2.7-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex (from fairseq->ai4bharat-transliteration)\n",
      "  Using cached regex-2019.12.20.tar.gz (679 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting urduhack (from ai4bharat-transliteration)\n",
      "  Using cached urduhack-0.2.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Using cached urduhack-0.2.5-py3-none-any.whl.metadata (5.7 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached urduhack-0.2.4-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Using cached urduhack-0.2.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Using cached urduhack-0.2.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Using cached urduhack-0.2.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached urduhack-0.1.4-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting omegaconf<2.1 (from fairseq->ai4bharat-transliteration)\n",
      "  Using cached omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\n",
      "\u001b[33mWARNING: Ignoring version 2.0.6 of omegaconf since it has invalid metadata:\n",
      "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl (from fairseq->ai4bharat-transliteration) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
      "    PyYAML (>=5.1.*)\n",
      "            ~~~~~~^\n",
      "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached omegaconf-2.0.5-py3-none-any.whl.metadata (3.0 kB)\n",
      "\u001b[33mWARNING: Ignoring version 2.0.5 of omegaconf since it has invalid metadata:\n",
      "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/e5/f6/043b6d255dd6fbf2025110cea35b87f4c5100a181681d8eab496269f0d5b/omegaconf-2.0.5-py3-none-any.whl (from fairseq->ai4bharat-transliteration) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
      "    PyYAML (>=5.1.*)\n",
      "            ~~~~~~^\n",
      "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: pip is looking at multiple versions of hydra-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fairseq (from ai4bharat-transliteration)\n",
      "  Using cached fairseq-0.12.1.tar.gz (9.6 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[16 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/slurm-mahardika.ihsani-61862/pip-build-env-ahj2564l/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 334, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=[])\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/slurm-mahardika.ihsani-61862/pip-build-env-ahj2564l/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 304, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/slurm-mahardika.ihsani-61862/pip-build-env-ahj2564l/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 320, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 27, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 18, in write_version_py\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: 'fairseq/version.txt'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install ai4bharat-transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Multilingual model for transliteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages/fairseq/checkpoint_utils.py:315: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(f, map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading language model probablitites dictionaries for rescoring module\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MB  0% (0 of 2.0) |                      | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      "MB100% (2.0 of 2.0) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succefully Downloaded to: /home/mahardika.ihsani/.conda/envs/cmix_neurons/lib/python3.10/site-packages/ai4bharat/transliteration/transformer/models/indic2en/v1.0/dicts.zip\n",
      "Initializing Multilingual model for transliteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dicts into RAM: 100%|██████████| 1/1 [00:00<00:00, 22.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from ai4bharat.transliteration import XlitEngine\n",
    "\n",
    "transliterator = XlitEngine(src_script_type=\"indic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mujhe lagata movie haye kii yeh dekhane key liye mulyavaan hah'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmix_neurons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
